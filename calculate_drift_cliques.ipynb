{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a2ec6d",
   "metadata": {},
   "source": [
    "# reviewing theorem 3\n",
    "\n",
    "- $C$: number of cases\n",
    "- $\\epsilon$: fraction of cases\n",
    "- $k$: the size of a set of *any* individuals in the population such that there are at least 2 individuals that differ on $\\epsilon C$ cases\n",
    "    - smaller $k$ makes this harder to achieve\n",
    "    - larger $\\epsilon$ makes this harder to achieve\n",
    "\n",
    "empirical question:\n",
    "- what is the smallest $k$, and largest $\\epsilon$, that satisfies these constraints?\n",
    "\n",
    "## approach\n",
    "\n",
    "- load pop error matrix, B\n",
    "- set $\\epsilon$ to some value\n",
    "\n",
    "- make NxN adjacency matrix where i,j indicates whether $n_i$ and $n_j$ differ on less than $\\epsilon$C cases\n",
    "- calculate the maximum clique of this matrix, whose size equals $k$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709bbf0",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "- compare behavioral diversity to values of k, epsilon\n",
    "    - calculate mean proportion of unique error vectors each gen\n",
    "- calculate best epsilon per generation? \n",
    "    - look at runtime fraction with optimal epsilon?\n",
    "    - what is the best runtime fraction using optimal epsilon, over generations?\n",
    "- compare empirical # evals for these runs to new estimate/bound of running time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2133542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_graph(G):\n",
    "    plt.figure()\n",
    "    nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb215e7c",
   "metadata": {},
   "source": [
    "# generate data\n",
    "- can turn this off if loading from saved state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "import itertools as it\n",
    "from tqdm.notebook import  tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "import signal\n",
    "import time\n",
    "import timeit \n",
    "    \n",
    "class TimeOutException(Exception):\n",
    "   pass\n",
    "\n",
    "def alarm_handler(signum, frame):\n",
    "#     print(\"ALARM signal received\")\n",
    "    raise TimeOutException()\n",
    "    \n",
    "MAXTIME = 10\n",
    "def average_different(x, y):\n",
    "    \"\"\"count the number of elements where x and y differ, divide by length\"\"\"\n",
    "    assert x.shape == y.shape\n",
    "    return (x != y).sum()/len(x)\n",
    "# for g in tqdm(df.generation.unique()):\n",
    "def save_runtime_stats(datadir, boolean):\n",
    "    comparison = hamming if boolean else average_different\n",
    "    filelist = list(glob(datadir+f'/*errors*.csv'))\n",
    "    print(f'\\n{datadir}, trials: {len(filelist)}, errors: {\"boolean\" if boolean else \"integer\"}\\n')\n",
    "    problem = datadir.split('lex-theory-')[-1].replace('-',' ').title()\n",
    "    for t,f in enumerate(tqdm(filelist, problem+' trials')):\n",
    "        frames = []\n",
    "        df = pd.read_csv(f)\n",
    "        for g in tqdm(df.generation.unique(), \n",
    "                      '--- '+ problem + f' trial {t}',\n",
    "                      leave=False):\n",
    "#         for g in df.generation.unique()[:50]:\n",
    "#         for g in df.generation.unique():\n",
    "            result = {}\n",
    "            B = df.loc[df.generation==g,[c for c in df.columns if 'TC' in c]]\n",
    "#             print('B shape:',B.shape)\n",
    "            pop_size = B.shape[0]\n",
    "            # remove duplicate arrays\n",
    "            B = B.drop_duplicates()\n",
    "            nunique = len(B)/pop_size\n",
    "            B = B.values\n",
    "            # calculate the determinant of the covariance matrix\n",
    "#             det_cov = np.linalg.det(np.cov(B))\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                X = np.corrcoef(B)\n",
    "                X = X[np.logical_not(np.isnan(X))]\n",
    "                mean_cov = np.mean(np.abs(X))\n",
    "#                 print('corrcoef:',X)\n",
    "#                 print('mean_cov:',mean_cov)\n",
    "            C = B.shape[1]\n",
    "            N = B.shape[0]\n",
    "            eps = 0.5\n",
    "            # pairwise distance\n",
    "            D = np.empty((N,N))\n",
    "            for i,j in it.product(np.arange(len(B)), repeat=2):\n",
    "                D[i,j] = comparison(B[i,:],B[j,:])\n",
    "            # epsilon\n",
    "            best_eps = None\n",
    "            runtimemin = None\n",
    "            subframes = []\n",
    "#             if problem != 'Compare String Lengths':\n",
    "#                 eps_range = np.linspace(0.05,0.6,12)  \n",
    "#             else:\n",
    "#                 np.linspace(0.05,0.45,9) \n",
    "            eps_range = np.linspace(0.05,0.6,12)  \n",
    "            for eps in tqdm(eps_range,\n",
    "                            '------ '+ problem + f' trial {t} gen {g}', \n",
    "                            leave=False): \n",
    "                A = D < eps\n",
    "                # max clique\n",
    "                G = nx.convert_matrix.from_numpy_matrix(A)\n",
    "                # define timeout signal\n",
    "                signal.signal(signal.SIGALRM, alarm_handler)\n",
    "                signal.alarm(MAXTIME)\n",
    "                start = time.process_time()\n",
    "                try:\n",
    "                    k = nx.algorithms.clique.graph_clique_number(G)\n",
    "                except TimeOutException as e:\n",
    "#                     print(e, 'problem:',problem, 'eps:',eps)\n",
    "#                     k = float('NaN')\n",
    "                    break\n",
    "                signal.alarm(0)\n",
    "                clique_time=time.process_time() - start\n",
    "#                 if problem == 'Compare String Lengths':\n",
    "#                     print('eps: ',eps, 'clique time: ', clique_time)\n",
    "                    \n",
    "                runtime = 4*N/eps + 2*k*C\n",
    "                \n",
    "                if best_eps == None:\n",
    "                    best_eps = eps\n",
    "                    runtimemin = runtime\n",
    "                elif runtime < runtimemin:\n",
    "                    best_eps = eps\n",
    "                    runtimemin = runtime\n",
    "                    \n",
    "                subframes.append({\n",
    "                    'problem':problem,\n",
    "                    'g':g,\n",
    "                    'pop_size':pop_size,\n",
    "                    'N':N,\n",
    "                    'k':k,\n",
    "                    'k%':round(k/N*100,2),\n",
    "                    'eps':eps,\n",
    "                    'runtime bound':runtime,\n",
    "                    'N*C': N*C,\n",
    "                    'runtime fraction': (runtime)/(N*C),\n",
    "                    'trial':t,\n",
    "                    'nunique':nunique,\n",
    "                    'mean_cov':mean_cov,\n",
    "                    'clique time': clique_time\n",
    "                })\n",
    "            for i,sf in enumerate(subframes):\n",
    "                subframes[i]['best_eps'] = best_eps\n",
    "                subframes[i]['runtime min'] = runtimemin\n",
    "                \n",
    "            frames += subframes\n",
    "    \n",
    "        print(f'saving stats for {f}')\n",
    "        res = pd.DataFrame.from_records(frames)\n",
    "        \n",
    "        res.to_csv(datadir+f'/runtime_stats-{t}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c06c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'data/lex-theory-'\n",
    "# popsize = '250'\n",
    "# problem = 'mirror-image'\n",
    "# problems = [\n",
    "#             ('compare-string-lengths',True,),\n",
    "#             ('count-odds',False),\n",
    "#             ('double-letters',False),\n",
    "#             ('last-index-of-zero',False),\n",
    "#             ('mirror-image',True),\n",
    "#             ('negative-to-zero',False)\n",
    "# ]\n",
    "problems = [\n",
    "            ('x-word-lines', False),\n",
    "            ('vector-average', False)\n",
    "#             ('compare-string-lengths',True,),\n",
    "#             ('count-odds',False),\n",
    "#             ('double-letters',False),\n",
    "#             ('last-index-of-zero',False),\n",
    "#             ('mirror-image',True),\n",
    "#             ('negative-to-zero',False)\n",
    "]\n",
    "# from multiprocessing import Pool\n",
    "from pqdm.processes import pqdm\n",
    "\n",
    "args =[(rootdir+name, boolean) for name,boolean in problems] \n",
    "pqdm(args, save_runtime_stats, n_jobs=len(args), argument_type='args')\n",
    "# with Pool(processes=len(problems)) as pool:\n",
    "#     pool.starmap(save_runtime_stats, args )\n",
    "#     for name, boolean in problems.items():\n",
    "#         datadir = rootdir+name\n",
    "#         save_runtime_stats(datadir, boolean) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
