{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing estimates of running time to experiments\n",
    "\n",
    "\n",
    "The goal here is to create four figures:\n",
    "\n",
    "## Figure 1: average pool size in each step of lexicase\n",
    "\n",
    "- predicted pool size:\n",
    "- actual pool size, averaged over generations and trials\n",
    "- a line representing N, the maximum pool size\n",
    "\n",
    "<!-- ## Figure 2: expected running time comparison\n",
    "\n",
    "boxplots of \n",
    "\n",
    "- sum of all actual lexicase pool sizes per lexicase selection event\n",
    "- sum of expected lexicase pool sizes ($\\bar{L}$ for boolean problems) per selection event (generation)\n",
    "- line at old theory: NT -->\n",
    "\n",
    "## Figure 3: running time as a function of the number of selections\n",
    "\n",
    "line plots of\n",
    "\n",
    "- actual running time ( $ d + \\sum_{i=0}^{d} { S_i} $) per selection event\n",
    "- expected running time ( $ \\hat{d} + \\sum_{i=0}^{\\hat{d}} { \\hat{S_i}} $) per selection event\n",
    "- line of $N*T*s$ where $s$ is the selection event number [1:gens*pop]\n",
    "\n",
    "## Figure 4: measured (actual) running time versus predicted running time\n",
    "\n",
    "scatterplot of\n",
    "\n",
    "- actual running time: $ d + \\sum_{i=0}^{d} { S_i} $\n",
    "- expected running time : $ a + b\\hat{d} + c\\sum_{i=0}^{\\hat{d}} { \\hat{S_i}} $) per selection event\n",
    "    - estimate a,b,c using linear regression\n",
    "    - report R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# what to capture:\n",
    "\n",
    "# data frame of: \n",
    "\n",
    "#   problem, \n",
    "#   trial, \n",
    "#   population size\n",
    "#   training case size\n",
    "#   generation, \n",
    "#   selection_event, \n",
    "#   selection_iteration, \n",
    "#   iteration_pool_size, \n",
    "#   selection_depth, \n",
    "#   average_error\n",
    "dfs = []\n",
    "problems = ['mirror-image',\n",
    "        'compare-string-lengths'\n",
    "       ]\n",
    "# fraction of generational selections to include\n",
    "sample_selection = .1\n",
    "\n",
    "for p in problems:\n",
    "    for d in glob('population-size-*/'+p):\n",
    "        pop_size = int(d.split('/')[0].split('population-size-')[-1])\n",
    "        print(p,'pop_size:',pop_size)\n",
    "    #     frames = []\n",
    "        frame = { \n",
    "            'problem':[],\n",
    "            'trial':[],\n",
    "            'generation':[],\n",
    "            'selection_event':[],\n",
    "            'selection_depth':[],\n",
    "            'selection_iteration':[],\n",
    "            'iteration_pool_size':[],\n",
    "            'starting_pool_size':[],\n",
    "            'N':pop_size\n",
    "        }\n",
    "        # load individuals remaining\n",
    "        print('\\tindividuals remaining...')\n",
    "        for f in tqdm(glob(d + '/individuals_*.csv')):\n",
    "            trial = int(f.split('individuals_remaining')[-1].split('.csv')[0])\n",
    "            sel_col_start = -1\n",
    "            gen_counter = {}\n",
    "            with open(f) as fp:\n",
    "                for cnt, line in enumerate(fp):\n",
    "                    vals  = line.split(',')\n",
    "                    if cnt == 0:\n",
    "                        sel_col_start = [i for i,v in enumerate(vals) if v == 'S0'][0]\n",
    "                        continue\n",
    "                    # only capture first sample_selection selection events per generation\n",
    "                    if vals[0] in gen_counter.keys():\n",
    "                        gen_counter[vals[0]] += 1\n",
    "                    else:\n",
    "                        gen_counter[vals[0]] = 1\n",
    "                    if gen_counter[vals[0]] > sample_selection*pop_size: \n",
    "                        continue\n",
    "                    for i, v in enumerate(vals[sel_col_start:]):\n",
    "                        v = v.strip()\n",
    "                        frame['problem'].append(p)\n",
    "                        frame['trial'].append(trial)\n",
    "                        frame['generation'].append(vals[0])\n",
    "                        frame['selection_event'].append( cnt)\n",
    "                        frame['selection_depth'].append( len(vals[sel_col_start:]))\n",
    "                        frame['selection_iteration'].append( i)\n",
    "                        frame['iteration_pool_size'].append( int(v))\n",
    "                        frame['starting_pool_size'].append( int(vals[sel_col_start]))\n",
    "    #                     frames.append(frame)\n",
    "        dfs.append(pd.DataFrame.from_records(frame))\n",
    "df = pd.concat(dfs)\n",
    "del dfs\n",
    "print('len(df):',len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load behaviors and merge with selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for p in problems:\n",
    "    for d in glob('population-size-*/'+p):\n",
    "        pop_size = int(d.split('/')[0].split('population-size-')[-1])\n",
    "        print(p,'pop_size:',pop_size)\n",
    "        print(d)\n",
    "        Lbar_frame = {'trial':[],\n",
    "                      'problem':[],\n",
    "                      'generation':[],\n",
    "                      'Lbar':[],\n",
    "                      'N':pop_size\n",
    "                     }\n",
    "        # now open the corresponding behaviors file\n",
    "        print('\\tbehaviors file...')\n",
    "        for f in tqdm(glob(d + '/behaviors_*.csv')):\n",
    "            trial = int(f.split('behaviors_and_errors')[-1].split('.csv')[0])\n",
    "            case_col_start = -1\n",
    "\n",
    "            Lbar = {}\n",
    "            with open(f) as fp:\n",
    "                population = 0\n",
    "                for cnt, line in enumerate(fp):\n",
    "                    vals  = line.split(',')\n",
    "                    if cnt == 0:\n",
    "                        case_col_start = [i for i,v in enumerate(vals) if v == 'TC0'][0]\n",
    "                        gen_col = [i for i,v in enumerate(vals) if v == 'generation'][0]\n",
    "                        continue\n",
    "                    T = len(vals[case_col_start:])\n",
    "                    mean_error = np.mean([float(v) for v in vals[case_col_start:]])\n",
    "                    if vals[gen_col] not in Lbar.keys():\n",
    "                        Lbar[vals[gen_col]] = 0.0\n",
    "\n",
    "                    Lbar[vals[gen_col]] += mean_error / pop_size\n",
    "\n",
    "            for i,v in Lbar.items():\n",
    "                Lbar_frame['trial'].append(trial)\n",
    "                Lbar_frame['problem'].append(p)\n",
    "                Lbar_frame['generation'].append(i)\n",
    "                Lbar_frame['Lbar'].append(v)\n",
    "\n",
    "        dfs.append(pd.DataFrame.from_records(Lbar_frame))\n",
    "                                         \n",
    "df_lbar = pd.concat(dfs)\n",
    "del dfs\n",
    "print('len(df_lbar):',len(df_lbar))\n",
    "\n",
    "df = df.merge(df_lbar, on = ['trial','generation','problem','N'])\n",
    "print('merged len(df):',len(df))\n",
    "        \n",
    "df['source'] = 'Actual'\n",
    "\n",
    "# print(df.columns)\n",
    "# for col in df.columns:\n",
    "#     print(col, df[col].nunique(), df[col].unique())\n",
    "    \n",
    "df.to_feather('loaded_sampled_data.feather')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running time estimates\n",
    "\n",
    "for boolean problems, \n",
    "\n",
    "$P_{surv}(i) = 1 - \\bar{L} + \\bar{L}^{S_i}$\n",
    "\n",
    "In this version, we have to simulate the values of $S_i$ (i.e. recurse) due to $P_{surv}$'s dependence on it. \n",
    "\n",
    "To remove dependence on iteration, it can be estimated as \n",
    "\n",
    "$\\hat{P}_{surv}(i) \\approx 1 - \\bar{L} $\n",
    "\n",
    "Where the expected depth is \n",
    "\n",
    "$\\hat{d} = log (\\hat{P}_{surv}) / log(N)$\n",
    "\n",
    "And\n",
    "\n",
    "$ \\hat{S} = N \\hat{P}^i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the pool sizes using the exact equation\n",
    "def boolean_next_pool_size(S, Lbar, i):\n",
    "    P_surv = 1  - Lbar + np.power(Lbar, S)\n",
    "    return S*P_surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "df_math = df[['problem', \n",
    "             'trial', \n",
    "             'starting_pool_size',\n",
    "             'generation', \n",
    "             'selection_event',\n",
    "             'Lbar',\n",
    "             'N'\n",
    "             ]].drop_duplicates()\n",
    "print('iterations to run:',len(df_math))\n",
    "math_frames = []\n",
    "simple_math_frames = []\n",
    "for idx, row in tqdm(df_math.iterrows(), total=len(df_math)):\n",
    "    math_dict = row.to_dict().copy()\n",
    "    math_dict['source'] = 'Simulated'\n",
    "    math_dict['selection_iteration'] = 0\n",
    "    math_dict['iteration_pool_size'] = math_dict['starting_pool_size']\n",
    "#     print('math_dict:',math_dict)\n",
    "    math_frames.append(math_dict)\n",
    "    S0 = row['starting_pool_size']\n",
    "    S = S0\n",
    "    i = 1\n",
    "    while S >= 2 and i < S0:\n",
    "        math_dict = row.to_dict().copy()\n",
    "        math_dict['selection_iteration'] = i\n",
    "        math_dict['source'] = 'Simulated'\n",
    "        S = boolean_next_pool_size(S, math_dict['Lbar'], i)\n",
    "        math_dict['iteration_pool_size'] = S\n",
    "        i += 1\n",
    "        if S >= 2 or i < S0:\n",
    "            math_dict['simulated_depth'] = i\n",
    "#         print('math_dict:',math_dict)\n",
    "        math_frames.append(math_dict)\n",
    "        \n",
    "    ######################################\n",
    "    # simpler math: loop til expected depth, E[S] = S0*(1-Lbar)^i just multiply E[d]*\n",
    "    ######################################\n",
    "    simple_math_dict = row.to_dict().copy()\n",
    "    simple_math_dict['source'] = 'Expectation'\n",
    "    P_surv = 1 - simple_math_dict['Lbar']\n",
    "    Ed = -np.log(S0)/np.log(P_surv)\n",
    "    simple_math_dict['selection_iteration'] = 0\n",
    "    simple_math_dict['iteration_pool_size'] = S0\n",
    "    simple_math_dict['expected_depth'] = Ed \n",
    "    simple_math_frames.append(simple_math_dict)\n",
    "    for i in np.arange(1,round(Ed)):\n",
    "        simple_math_dict = row.to_dict().copy()\n",
    "        simple_math_dict['source'] = 'Expectation'\n",
    "        simple_math_dict['selection_iteration'] = i\n",
    "        simple_math_dict['iteration_pool_size'] = S0*np.power(P_surv,i)\n",
    "        simple_math_dict['expected_depth'] = Ed \n",
    "        simple_math_frames.append(simple_math_dict)\n",
    "\n",
    "df_simulation = pd.DataFrame.from_records(math_frames)\n",
    "df_simulation.to_feather('simulated_data.feather')\n",
    "\n",
    "df_exp = pd.DataFrame.from_records(simple_math_frames)\n",
    "df_exp.to_feather('expectation_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done preprocessing. clearing data.')\n",
    "del df\n",
    "del df_simulation\n",
    "del df_exp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
